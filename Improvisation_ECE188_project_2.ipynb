{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE 188 Unfinished Musical Project\n",
    "\n",
    "This part of the project basically runs on the google collab. This is just the example code that I use, and also to show the plots of the results. The link for the google collab is in the technical implementation portion of the README.md in this github.\n",
    "\n",
    "The goal of this part is to generate the continuation as well as accompaniment of musical pieces\n",
    "\n",
    "Before, we begin anything we have to perform the environmental setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDMQbHPYVKmV"
   },
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "tciXVi5eWG_1"
   },
   "outputs": [],
   "source": [
    "!gsutil -q -m cp -r gs://magentadata/models/music_transformer/* /content/\n",
    "!gsutil -q -m cp gs://magentadata/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2 /content/\n",
    "!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev\n",
    "!pip install -qU magenta pyfluidsynth\n",
    "\n",
    "import ctypes.util\n",
    "def proxy_find_library(lib):\n",
    "  if lib == 'fluidsynth':\n",
    "    return 'libfluidsynth.so.1'\n",
    "  else:\n",
    "    return ctypes.util.find_library(lib)\n",
    "ctypes.util.find_library = proxy_find_library\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "from tensor2tensor.utils import decoding\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "\n",
    "import magenta.music as mm\n",
    "from magenta.models.score2perf import score2perf\n",
    "\n",
    "SF2_PATH = '/content/Yamaha-C5-Salamander-JNv5.1.sf2'\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "def upload_midi():\n",
    "  data = list(files.upload().values())\n",
    "  if len(data) > 1:\n",
    "    print('Multiple files uploaded; using only one.')\n",
    "  return mm.midi_to_note_sequence(data[0])\n",
    "\n",
    "def decode(ids, encoder):\n",
    "  ids = list(ids)\n",
    "  if text_encoder.EOS_ID in ids:\n",
    "    ids = ids[:ids.index(text_encoder.EOS_ID)]\n",
    "  return encoder.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jMjrtSKxYloO"
   },
   "source": [
    "### Set up the Melody-conditioned Transformer model\n",
    "Skip this part if the accompaniment for the music is not missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "CFnUHAk1g_rc"
   },
   "outputs": [],
   "source": [
    "model_name = 'transformer'\n",
    "hparams_set = 'transformer_tpu'\n",
    "ckpt_path = '/content/checkpoints/melody_conditioned_model_16.ckpt'\n",
    "\n",
    "class MelodyToPianoPerformanceProblem(score2perf.AbsoluteMelody2PerfProblem):\n",
    "  @property\n",
    "  def add_eos_symbol(self):\n",
    "    return True\n",
    "\n",
    "problem = MelodyToPianoPerformanceProblem()\n",
    "melody_conditioned_encoders = problem.get_feature_encoders()\n",
    "hparams = trainer_lib.create_hparams(hparams_set=hparams_set)\n",
    "trainer_lib.add_problem_hparams(hparams, problem)\n",
    "hparams.num_hidden_layers = 16\n",
    "hparams.sampling_method = 'random'\n",
    "decode_hparams = decoding.decode_hparams()\n",
    "decode_hparams.alpha = 0.0\n",
    "decode_hparams.beam_size = 1\n",
    "run_config = trainer_lib.create_run_config(hparams)\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    model_name, hparams, run_config,\n",
    "    decode_hparams=decode_hparams)\n",
    "\n",
    "inputs = []\n",
    "decode_length = 0\n",
    "\n",
    "def input_generator():\n",
    "  global inputs\n",
    "  while True:\n",
    "    yield {\n",
    "        'inputs': np.array([[inputs]], dtype=np.int32),\n",
    "        'targets': np.zeros([1, 0], dtype=np.int32),\n",
    "        'decode_length': np.array(decode_length, dtype=np.int32)\n",
    "    }\n",
    "\n",
    "input_fn = decoding.make_input_fn_from_generator(input_generator())\n",
    "melody_conditioned_samples = estimator.predict(\n",
    "    input_fn, checkpoint_path=ckpt_path)\n",
    "\n",
    "_ = next(melody_conditioned_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "xqWN4dEDLVdQ"
   },
   "outputs": [],
   "source": [
    "event_padding = 2 * [mm.MELODY_NO_EVENT]\n",
    "melody = 'Upload'  \n",
    "\n",
    "if melody == 'Upload':\n",
    "\n",
    "  melody_ns = upload_midi()\n",
    "  melody_instrument = mm.infer_melody_for_sequence(melody_ns)\n",
    "  notes = [note for note in melody_ns.notes\n",
    "           if note.instrument == melody_instrument]\n",
    "  del melody_ns.notes[:]\n",
    "  melody_ns.notes.extend(\n",
    "      sorted(notes, key=lambda note: note.start_time))\n",
    "  for i in range(len(melody_ns.notes) - 1):\n",
    "    melody_ns.notes[i].end_time = melody_ns.notes[i + 1].start_time\n",
    "  inputs = melody_conditioned_encoders['inputs'].encode_note_sequence(\n",
    "      melody_ns)\n",
    "else:\n",
    "\n",
    "  events = [event + 12 if event != mm.MELODY_NO_EVENT else event\n",
    "            for e in melodies[melody]\n",
    "            for event in [e] + event_padding]\n",
    "  inputs = melody_conditioned_encoders['inputs'].encode(\n",
    "      ' '.join(str(e) for e in events))\n",
    "  melody_ns = mm.Melody(events).to_sequence(qpm=150)\n",
    "  \n",
    "mm.plot_sequence(melody_ns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cL05hhAbCc1b"
   },
   "source": [
    "### The plots of the generated sequence can be examine below.\n",
    "The files can also be listen through the 'input' folder as well as the 'sample generated output' folder in each of the titled songs folders.\n",
    "\n",
    "This plot here is the piece from TAPS (Butterfield's Lullaby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Butterfield_1.png\" alt=\"plot\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the accompaniment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "WnAZsIYsfXWV"
   },
   "outputs": [],
   "source": [
    "decode_length = 4096\n",
    "sample_ids = next(melody_conditioned_samples)['outputs']\n",
    "\n",
    "midi_filename = decode(\n",
    "    sample_ids,\n",
    "    encoder=melody_conditioned_encoders['targets'])\n",
    "accompaniment_ns = mm.midi_file_to_note_sequence(midi_filename)\n",
    "\n",
    "mm.plot_sequence(accompaniment_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Butterfield_2.png\" alt=\"plot\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "2fFhZbhIeS2f"
   },
   "outputs": [],
   "source": [
    "mm.sequence_proto_to_midi_file(\n",
    "    accompaniment_ns, '/tmp/TAPS_accompaniment.mid')\n",
    "files.download('/tmp/TAPS_accompaniment.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl3oY0w8gBJh"
   },
   "source": [
    "# Load the piano performance language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "PBngSJvP_En7"
   },
   "outputs": [],
   "source": [
    "model_name = 'transformer'\n",
    "hparams_set = 'transformer_tpu'\n",
    "ckpt_path = '/content/checkpoints/unconditional_model_16.ckpt'\n",
    "\n",
    "class PianoPerformanceLanguageModelProblem(score2perf.Score2PerfProblem):\n",
    "  @property\n",
    "  def add_eos_symbol(self):\n",
    "    return True\n",
    "\n",
    "problem = PianoPerformanceLanguageModelProblem()\n",
    "unconditional_encoders = problem.get_feature_encoders()\n",
    "\n",
    "hparams = trainer_lib.create_hparams(hparams_set=hparams_set)\n",
    "trainer_lib.add_problem_hparams(hparams, problem)\n",
    "hparams.num_hidden_layers = 16\n",
    "hparams.sampling_method = 'random'\n",
    "\n",
    "decode_hparams = decoding.decode_hparams()\n",
    "decode_hparams.alpha = 0.0\n",
    "decode_hparams.beam_size = 1\n",
    "\n",
    "run_config = trainer_lib.create_run_config(hparams)\n",
    "estimator = trainer_lib.create_estimator(\n",
    "    model_name, hparams, run_config,\n",
    "    decode_hparams=decode_hparams)\n",
    "\n",
    "def input_generator():\n",
    "  global targets\n",
    "  global decode_length\n",
    "  while True:\n",
    "    yield {\n",
    "        'targets': np.array([targets], dtype=np.int32),\n",
    "        'decode_length': np.array(decode_length, dtype=np.int32)\n",
    "    }\n",
    "\n",
    "targets = []\n",
    "decode_length = 0\n",
    "\n",
    "input_fn = decoding.make_input_fn_from_generator(input_generator())\n",
    "unconditional_samples = estimator.predict(\n",
    "    input_fn, checkpoint_path=ckpt_path)\n",
    "\n",
    "_ = next(unconditional_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVF5IKpNKeSx"
   },
   "outputs": [],
   "source": [
    "primer = 'Upload'  #Upload the songs.\n",
    "\n",
    "if primer == 'Upload':\n",
    "  primer_ns = upload_midi()\n",
    "\n",
    "primer_ns = mm.apply_sustain_control_changes(primer_ns)\n",
    "\n",
    "max_primer_seconds = 6  \n",
    "if primer_ns.total_time > max_primer_seconds:\n",
    "  print('Primer is longer than %d seconds, truncating.' % max_primer_seconds)\n",
    "  primer_ns = mm.extract_subsequence(\n",
    "      primer_ns, 0, max_primer_seconds)\n",
    "\n",
    "if any(note.is_drum for note in primer_ns.notes):\n",
    "  print('Primer contains drums; they will be removed.')\n",
    "  notes = [note for note in primer_ns.notes if not note.is_drum]\n",
    "  del primer_ns.notes[:]\n",
    "  primer_ns.notes.extend(notes)\n",
    "\n",
    "for note in primer_ns.notes:\n",
    "  note.instrument = 1\n",
    "  note.program = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Improvisation and plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "3Wz54NrSJY87"
   },
   "outputs": [],
   "source": [
    "targets = unconditional_encoders['targets'].encode_note_sequence(\n",
    "    primer_ns)\n",
    "\n",
    "targets = targets[:-1]\n",
    "\n",
    "decode_length = max(0, 4096 - len(targets))\n",
    "if len(targets) >= 4096:\n",
    "  print('No generation...')\n",
    "\n",
    "sample_ids = next(unconditional_samples)['outputs']\n",
    "\n",
    "midi_filename = decode(\n",
    "    sample_ids,\n",
    "    encoder=unconditional_encoders['targets'])\n",
    "ns = mm.midi_file_to_note_sequence(midi_filename)\n",
    "\n",
    "continuation_ns = mm.concatenate_sequences([primer_ns, ns])\n",
    "\n",
    "mm.plot_sequence(continuation_ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### The files can also be listen through the 'input' folder as well as the 'sample generated output' folder in each of the titled songs folders.\n",
    "\n",
    "\n",
    "Generated improvisation for Butterfield's Lullaby piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Butterfield_4.png\" alt=\"plot\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Butterfield_5.png\" alt=\"plot\" style=\"width: 470px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated improvisation for Mozart's Requiem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Mozart_1.png\" alt=\"plot\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated improvisation for Turandot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Turandot_1.png\" alt=\"plot\" style=\"width: 470px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Turandot_2.png\" alt=\"plot\" style=\"width: 490px;\"/>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ECE_188_project_2.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
